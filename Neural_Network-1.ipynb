{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Network dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', newline='') as f:\n",
    "            reader = csv.reader(f)#속성 85개\n",
    "            data = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [2, 4, 5, 7, 8, 9, 10, 11, 12, 70, 71, 72]\n",
    "target_list = [[0] if data[i][84] == 'BENIGN' else [1] for i in range(len(data))]\n",
    "\n",
    "y_train = np.array(target_list[1:]).astype(np.float32)\n",
    "X_train = np.array(data[1:])[:,col].astype(np.float32)\n",
    "attribute = np.array(data[0])[col] \n",
    "#Benign 0, DDos 1\n",
    "mean = [38257.566, 8879.619, 7.600288, 16241648.0, 4.8749166, 4.5727744,\n",
    "     939.46344, 5960.4766, 538.53564, 4.5727744, 5960.4766, 4247.437]\n",
    "std = [23057.252, 19754.605, 3.8815773, 31524304.0, 15.42284,21.755308, \n",
    "       3249.3965, 39218.25, 1864.1251, 21.755308, 39218.25, 8037.763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    X_train[:,i] = (X_train[:,i] - mean[i])/std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use gpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # CUDA 장치 객체(device object)로\n",
    "    print(\"use gpu\")\n",
    "else:\n",
    "    print(\"use cpu\")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 120)\n",
    "        #self.fc2 = nn.Linear(120, 120)\n",
    "        self.fc3 = nn.Linear(120, 84)\n",
    "        self.fc4 = nn.Linear(84, 1)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        #x = x.to(device)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = self.fc4(x)\n",
    "        #x = torch.sigmoid(x) # drop out X \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_all(model, init_func, *params, **kwargs):\n",
    "    for p in model.parameters():\n",
    "        init_func(p, *params, **kwargs)\n",
    "\n",
    "\n",
    "#init_all(net, torch.nn.init.normal_, mean=0., std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "#criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch 1 fold validation loss : 0.2613063945377168 => Accuracy of the network on the validation: 70 %\n",
      "1 epoch 2 fold validation loss : 0.07685751358615237 => Accuracy of the network on the validation: 89 %\n",
      "1 epoch 3 fold validation loss : 0.03510542189365364 => Accuracy of the network on the validation: 94 %\n",
      "1 epoch 4 fold validation loss : 0.03595601636611427 => Accuracy of the network on the validation: 95 %\n",
      "1 epoch 5 fold validation loss : 0.16935091527024546 => Accuracy of the network on the validation: 82 %\n",
      "2 epoch 1 fold validation loss : 0.10451438516522192 => Accuracy of the network on the validation: 88 %\n",
      "2 epoch 2 fold validation loss : 0.022065627637183137 => Accuracy of the network on the validation: 96 %\n",
      "2 epoch 3 fold validation loss : 0.013787822944161475 => Accuracy of the network on the validation: 97 %\n",
      "2 epoch 4 fold validation loss : 0.021226676166789048 => Accuracy of the network on the validation: 97 %\n",
      "2 epoch 5 fold validation loss : 0.11677459149111181 => Accuracy of the network on the validation: 87 %\n",
      "3 epoch 1 fold validation loss : 0.07524167098868376 => Accuracy of the network on the validation: 91 %\n",
      "3 epoch 2 fold validation loss : 0.015708901539343532 => Accuracy of the network on the validation: 97 %\n",
      "3 epoch 3 fold validation loss : 0.009260921380338578 => Accuracy of the network on the validation: 98 %\n",
      "3 epoch 4 fold validation loss : 0.01599229607772282 => Accuracy of the network on the validation: 97 %\n",
      "3 epoch 5 fold validation loss : 0.08695500501157746 => Accuracy of the network on the validation: 90 %\n",
      "4 epoch 1 fold validation loss : 0.05788455973053039 => Accuracy of the network on the validation: 93 %\n",
      "4 epoch 2 fold validation loss : 0.012948513702294053 => Accuracy of the network on the validation: 98 %\n",
      "4 epoch 3 fold validation loss : 0.0072576851476557685 => Accuracy of the network on the validation: 98 %\n",
      "4 epoch 4 fold validation loss : 0.0131497329586888 => Accuracy of the network on the validation: 98 %\n",
      "4 epoch 5 fold validation loss : 0.06812439133576755 => Accuracy of the network on the validation: 92 %\n",
      "5 epoch 1 fold validation loss : 0.04790676323998262 => Accuracy of the network on the validation: 94 %\n",
      "5 epoch 2 fold validation loss : 0.010795941999497701 => Accuracy of the network on the validation: 98 %\n",
      "5 epoch 3 fold validation loss : 0.006720331687152344 => Accuracy of the network on the validation: 98 %\n",
      "5 epoch 4 fold validation loss : 0.01093913671903791 => Accuracy of the network on the validation: 98 %\n",
      "5 epoch 5 fold validation loss : 0.05520591382657211 => Accuracy of the network on the validation: 93 %\n",
      "--------------------------------------------------------------------------------------\n",
      "Finished Training\n",
      "average accuraccy : 93.0\n",
      "Precision : 0.03769697621464729, Recall : 0.9753565192222595, F1-score : 0.07258845120668411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.autograd import Variable\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "kfold =KFold(n_splits=5)\n",
    "avg_accuracy = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "sum_incorrect = 0\n",
    "for epoch in range(5):\n",
    "    fold = 0\n",
    "    for  train_index, test_index in kfold.split(X_train, y_train): \n",
    "            x_train_fold = X_train[train_index]\n",
    "            x_val_fold = X_train[test_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            y_val_fold = y_train[test_index]\n",
    "            fold += 1\n",
    "            #print(x_train_fold.shape)\n",
    "            for i in range(len(x_train_fold)//100):\n",
    "                # get the inputs\n",
    "                inputs = torch.tensor(x_train_fold[100*i:100*i+100])\n",
    "                labels = torch.tensor(y_train_fold[100*i:100*i+100])\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                #print(outputs)\n",
    "                #print(labels)\n",
    "                labels = labels.to(device)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            incorrect = 0\n",
    "            total = 0\n",
    "            for i in range(len(x_val_fold)//100):\n",
    "                # get the inputs\n",
    "                inputs = torch.tensor(x_val_fold[100*i:100*i+100])\n",
    "                labels = torch.tensor(y_val_fold[100*i:100*i+100])\n",
    "                outputs = net(inputs)\n",
    "                #print(outputs[1])\n",
    "                labels = labels.to(device)\n",
    "                loss = criterion(outputs, labels)\n",
    "                outputs[outputs > 0.5] = 1\n",
    "                outputs[outputs <= 0.5] = 0\n",
    "                result = labels - outputs\n",
    "                result_abs = abs(result)\n",
    "                FN += ((result+result_abs).sum())/2\n",
    "                TP += (labels + outputs - result_abs).sum()/2\n",
    "                total += len(outputs)\n",
    "                incorrect += result_abs.sum()\n",
    "                    # print statistics\n",
    "                running_loss += float(loss.item())\n",
    "                #print(\"FN {} FP {} TP {}\".format(FN, FP, TP))\n",
    "            sum_incorrect += incorrect\n",
    "            accuracy = 100 * (total - incorrect) / total\n",
    "            avg_accuracy += accuracy\n",
    "            print('{} epoch {} fold validation loss : {}'.format(epoch+1,fold, running_loss/len(x_val_fold)), end=\"\")\n",
    "            print(' => Accuracy of the network on the validation: %d %%' % (accuracy))\n",
    "            running_loss = 0.0\n",
    "                \n",
    "FP = (sum_incorrect - FN)\n",
    "Precision = TP/(TP + FP)\n",
    "Recall = TP/(TP + FN)\n",
    "print(\"--------------------------------------------------------------------------------------\")\n",
    "print('Finished Training')\n",
    "print(\"average accuraccy : {}\".format(avg_accuracy//25))\n",
    "print(\"Precision : {}, Recall : {}, F1-score : {}\".format(Precision, Recall, 2*((Precision*Recall)/(Precision+Recall))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with parameter random initialization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
